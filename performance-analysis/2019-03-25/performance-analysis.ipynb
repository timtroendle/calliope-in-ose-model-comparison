{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring impact of tolerances on Gurobi\n",
    "\n",
    "Following the first analysis, I slightly improved the numerics of the model through scaling and I am assessing the performance again in here. The numerical ranges now look like this:\n",
    "\n",
    "```\n",
    "Matrix range     [1e-05, 4e+02]\n",
    "Objective range  [1e+00, 1e+00]\n",
    "Bounds range     [5e-02, 2e+03]\n",
    "RHS range        [7e-03, 2e+03]\n",
    "```\n",
    "\n",
    "With a matrix range of 1e7 and an RHS range of 1e6 they are far from being perfect, but better than last time.\n",
    "\n",
    "In here we analyse the result of Gurobi runs using the same model but different parameter options. I used the `baseline` scenario and changed the `OptimalityTol` and `FeasibilityTol` values of Gurobi to:\n",
    "\n",
    "* 1e-6 (default value)\n",
    "* 1e-5\n",
    "* 1e-4\n",
    "* 1e-3\n",
    "* 1e-2 (max value)\n",
    "\n",
    "The hope being, that the result remains the same (remains close enough) but that solution time drops. Let's see whether that actually worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOLVE_DURATION_PREFIX = \"SOLVER   Solved in\"\n",
    "SOLUTION_PREFIX = \"SOLVER   Optimal objective\"\n",
    "\n",
    "\n",
    "def _preprocess_log(path_to_log):\n",
    "    path_to_log = Path(path_to_log)\n",
    "    with path_to_log.open(\"r\") as log_file:\n",
    "        lines = log_file.readlines()\n",
    "    return [line[22:] for line in lines]\n",
    "    \n",
    "\n",
    "def parse_solution_time(path_to_log):\n",
    "    lines = _preprocess_log(path_to_log)\n",
    "    duration_line = list(filter(lambda line: line.startswith(SOLVE_DURATION_PREFIX), lines))[0]\n",
    "    return float(re.findall('\\d+.?\\d+', duration_line)[1])\n",
    "\n",
    "\n",
    "def parse_iterations(path_to_log):\n",
    "    lines = _preprocess_log(path_to_log)\n",
    "    iterations_line = list(filter(lambda line: line.startswith(SOLVE_DURATION_PREFIX), lines))[0]\n",
    "    return float(re.findall('\\d+.?\\d+', iterations_line)[0])\n",
    "\n",
    "\n",
    "def parse_solution(path_to_log):\n",
    "    lines = _preprocess_log(path_to_log)\n",
    "    solution_line = list(filter(lambda line: line.startswith(SOLUTION_PREFIX), lines))[0]\n",
    "    return float(re.findall('\\d+.?\\d+e?\\+?\\d+', solution_line)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_runs(path_to_root_folder):\n",
    "    durations = [parse_solution_time(path) for path in Path(path_to_root_folder).glob(\"*.log\")]\n",
    "    solutions = [parse_solution(path) for path in Path(path_to_root_folder).glob(\"*.log\")]\n",
    "    iterations = [parse_iterations(path) for path in Path(path_to_root_folder).glob(\"*.log\")]\n",
    "    \n",
    "    mean, std = stats.norm.fit(solutions)\n",
    "    print(f\"Gurobi found the following optimal value on average: {mean} (std {std}).\")\n",
    "    mean, std = stats.norm.fit(iterations)\n",
    "    print(f\"Gurobi needed on average {mean:.0f} (std {std:.0f}) iterations to find the optimal value.\")\n",
    "    mean, std = stats.norm.fit(durations)\n",
    "    print(f\"Gurobi needed on average {mean:.0f}s (std {std:.0f}s) to find the optimal value.\")\n",
    "\n",
    "    \n",
    "def diff(path_to_root_folder, path_to_root_folder_of_base):\n",
    "    durations = [parse_solution_time(path) for path in Path(path_to_root_folder).glob(\"*.log\")]\n",
    "    solutions = [parse_solution(path) for path in Path(path_to_root_folder).glob(\"*.log\")]\n",
    "    iterations = [parse_iterations(path) for path in Path(path_to_root_folder).glob(\"*.log\")]\n",
    "    \n",
    "    base_durations = [parse_solution_time(path) for path in Path(path_to_root_folder_of_base).glob(\"*.log\")]\n",
    "    base_solutions = [parse_solution(path) for path in Path(path_to_root_folder_of_base).glob(\"*.log\")]\n",
    "    base_iterations = [parse_iterations(path) for path in Path(path_to_root_folder_of_base).glob(\"*.log\")]\n",
    "    \n",
    "    mean, std = stats.norm.fit(solutions)\n",
    "    mean_base, std_base = stats.norm.fit(base_solutions)\n",
    "    print(f\"Relative diff of objective average to base: {mean / mean_base}\")\n",
    "    mean, std = stats.norm.fit(iterations)\n",
    "    mean_base, std_base = stats.norm.fit(base_iterations)\n",
    "    print(f\"Relative diff of iterations average to base: {mean / mean_base}\")\n",
    "    mean, std = stats.norm.fit(durations)\n",
    "    mean_base, std_base = stats.norm.fit(base_durations)\n",
    "    print(f\"Relative diff of durations average to base: {mean / mean_base}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tolerances e-6\n",
      "--------------\n",
      "Gurobi found the following optimal value on average: 336375.605 (std 0.0).\n",
      "Gurobi needed on average 2170133 (std 0) iterations to find the optimal value.\n",
      "Gurobi needed on average 11054s (std 1709s) to find the optimal value.\n",
      "\n",
      "Tolerances e-5\n",
      "--------------\n",
      "Gurobi found the following optimal value on average: 336375.602 (std 0.0).\n",
      "Gurobi needed on average 837156 (std 0) iterations to find the optimal value.\n",
      "Gurobi needed on average 1223s (std 200s) to find the optimal value.\n",
      "Relative diff of objective average to base: 0.9999999910813985\n",
      "Relative diff of iterations average to base: 0.38576253160520574\n",
      "Relative diff of durations average to base: 0.11060621371797613\n",
      "\n",
      "Tolerances e-4\n",
      "--------------\n",
      "Gurobi found the following optimal value on average: 336375.62600000005 (std 5.820766091346741e-11).\n",
      "Gurobi needed on average 616935 (std 0) iterations to find the optimal value.\n",
      "Gurobi needed on average 13482s (std 1972s) to find the optimal value.\n",
      "Relative diff of objective average to base: 1.0000000624302112\n",
      "Relative diff of iterations average to base: 0.2842844194342006\n",
      "Relative diff of durations average to base: 1.2196588034335878\n",
      "\n",
      "Tolerances e-3\n",
      "--------------\n",
      "All runs needed more than 24h and were killed by the cluster.\n",
      "\n",
      "Tolerances e-2\n",
      "--------------\n",
      "All runs needed more than 24h and were killed by the cluster.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Tolerances e-6\")\n",
    "print(\"--------------\")\n",
    "analyse_runs(\"minus6/\")\n",
    "print()\n",
    "print(\"Tolerances e-5\")\n",
    "print(\"--------------\")\n",
    "analyse_runs(\"minus5/\")\n",
    "diff(\"minus5/\", \"minus6/\")\n",
    "print()\n",
    "print(\"Tolerances e-4\")\n",
    "print(\"--------------\")\n",
    "analyse_runs(\"minus4/\")\n",
    "diff(\"minus4/\", \"minus6/\")\n",
    "print()\n",
    "print(\"Tolerances e-3\")\n",
    "print(\"--------------\")\n",
    "print(\"All runs needed more than 24h and were killed by the cluster.\")\n",
    "print()\n",
    "print(\"Tolerances e-2\")\n",
    "print(\"--------------\")\n",
    "print(\"All runs needed more than 24h and were killed by the cluster.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Whenever a result was found, the solution was close to the reference. So it seems save to play around with the two parameters. In terms of runtime, there seems to be a sweet spot at 1e-5: compared to the reference, the result was found 10 times faster. Compared to the worst performance, it was even almost 100 times faster. It is not intuitive that the performance becomes better moving from 1e-6 to 1e-5 and then becomes worse and worse the larger the tolerances gets. Possible explanations may be (a) that it's the combination of the two parameters, (b) that it's due to the remaining numerical difficulties of the problem, or (c) that it's unrelated to the parameters values. Further tests would be necessary to verify or deny these hypotheses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "It's difficult to give advices based on these results. What I can say is that the performance is drastically impacted by the two parameters, and the correcteness of the solution does seem to be very insensitive to the parameters.\n",
    "\n",
    "It's impossible to suggest a certain parameter value based on the results. But, because the variation between the results for same parameter values isn't huge, it may make sense to test the parameter values for a certain model. Either on a reduced model before running the full model, or on the full model before running sensitivitiy analyses with loads of runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
